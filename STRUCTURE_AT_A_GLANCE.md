# Project Structure - At a Glance

## Current Layout

```
News-Calendar/
â”‚
â”œâ”€â”€ ğŸ“– DOCUMENTATION (Start Here)
â”‚   â”œâ”€â”€ SCRAPER_ARCHITECTURE_ANALYSIS.md    â† System deep dive
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md                â† Development roadmap
â”‚   â”œâ”€â”€ REORGANIZATION_SUMMARY.md           â† What we did
â”‚   â””â”€â”€ STRUCTURE_AT_A_GLANCE.md            â† This file
â”‚
â”œâ”€â”€ ğŸ“š REFERENCE (Learn From This)
â”‚   â””â”€â”€ old_structure/
â”‚       â”œâ”€â”€ FINAL_TOOLS_OUTPUT/
â”‚       â”‚   â”œâ”€â”€ scraper_core.py             â† Core scraping
â”‚       â”‚   â”œâ”€â”€ database.py                 â† DB operations
â”‚       â”‚   â”œâ”€â”€ daily_sync.py               â† Job example
â”‚       â”‚   â”œâ”€â”€ realtime_fetcher.py         â† Real-time example
â”‚       â”‚   â””â”€â”€ ... (other utilities)
â”‚       â””â”€â”€ github_workflows/               â† Old automation
â”‚
â”œâ”€â”€ ğŸš€ NEW IMPLEMENTATION (Build Here)
â”‚   â””â”€â”€ scraper_2.2/
â”‚       â”œâ”€â”€ README.md                       â† Getting started
â”‚       â”œâ”€â”€ requirements.txt                â† Dependencies
â”‚       â”œâ”€â”€ config.yaml                     â† Config template
â”‚       â”œâ”€â”€ .env.example                    â† Env template
â”‚       â”‚
â”‚       â”œâ”€â”€ src/                            â† Core classes
â”‚       â”‚   â”œâ”€â”€ scraper.py                  â† (to implement)
â”‚       â”‚   â”œâ”€â”€ database.py                 â† (to implement)
â”‚       â”‚   â”œâ”€â”€ cache.py                    â† (to implement)
â”‚       â”‚   â””â”€â”€ utils.py                    â† (to implement)
â”‚       â”‚
â”‚       â”œâ”€â”€ jobs/                           â† Job scripts
â”‚       â”‚   â”œâ”€â”€ bulk_fetcher.py             â† (to implement)
â”‚       â”‚   â”œâ”€â”€ realtime_updater.py         â† (to implement)
â”‚       â”‚   â””â”€â”€ scheduler.py                â† (to implement)
â”‚       â”‚
â”‚       â”œâ”€â”€ tests/                          â† Unit tests
â”‚       â”‚   â”œâ”€â”€ test_scraper.py             â† (to implement)
â”‚       â”‚   â”œâ”€â”€ test_cache.py               â† (to implement)
â”‚       â”‚   â””â”€â”€ test_database.py            â† (to implement)
â”‚       â”‚
â”‚       â”œâ”€â”€ logs/                           â† Application logs
â”‚       â”‚   â””â”€â”€ .gitkeep
â”‚       â”‚
â”‚       â””â”€â”€ docs/
â”‚           â”œâ”€â”€ ARCHITECTURE.md             â† (to implement)
â”‚           â””â”€â”€ MIGRATION_GUIDE.md          â† (to implement)
â”‚
â””â”€â”€ âš™ï¸ GITHUB AUTOMATION (Reference)
    â””â”€â”€ .github/
        â””â”€â”€ workflows/
            â”œâ”€â”€ monthly-updater.yml
            â”œâ”€â”€ daily-sync.yml
            â””â”€â”€ realtime-fetcher.yml
```

---

## Quick Navigation

### ğŸ¯ I Want To...

**Understand how the scraper works**
â†’ Read `SCRAPER_ARCHITECTURE_ANALYSIS.md`
â†’ Study `old_structure/FINAL_TOOLS_OUTPUT/scraper_core.py`

**See the development plan**
â†’ Read `PROJECT_STRUCTURE.md`
â†’ Section: "Implementation Map"

**Start building the new system**
â†’ Read `scraper_2.2/README.md`
â†’ Follow "Quick Start" section

**Learn from existing code**
â†’ Open `old_structure/FINAL_TOOLS_OUTPUT/`
â†’ Read scraper_core.py (308 lines)
â†’ Read database.py (321 lines)

**Understand the data flow**
â†’ Read `SCRAPER_ARCHITECTURE_ANALYSIS.md`
â†’ Section: "Data Flow Diagram"

**See what was reorganized**
â†’ Read `REORGANIZATION_SUMMARY.md`
â†’ Section: "What Was Done"

**Reference old job patterns**
â†’ Study `old_structure/FINAL_TOOLS_OUTPUT/daily_sync.py`
â†’ Study `old_structure/FINAL_TOOLS_OUTPUT/realtime_fetcher.py`

---

## ğŸ“Š System Overview

### Three Job Frequencies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Old System (What Currently Exists)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ MONTHLY (1st of month, 12:00 UTC)                      â”‚
â”‚ â””â”€ Backfill previous month + next 3 months             â”‚
â”‚    â””â”€ Run: monthly_updater.py                          â”‚
â”‚    â””â”€ Scrape: Full 4-month window                      â”‚
â”‚    â””â”€ Action: Insert to DB                             â”‚
â”‚                                                         â”‚
â”‚ DAILY (6:00 AM UTC)                                    â”‚
â”‚ â””â”€ Refresh past 3 days + next 7 days                   â”‚
â”‚    â””â”€ Run: daily_sync.py                               â”‚
â”‚    â””â”€ Scrape: 10-day window                            â”‚
â”‚    â””â”€ Action: Insert new + Update actuals              â”‚
â”‚                                                         â”‚
â”‚ REAL-TIME (Every 5 minutes)                            â”‚
â”‚ â””â”€ Update actual values for today                      â”‚
â”‚    â””â”€ Run: realtime_fetcher.py                         â”‚
â”‚    â””â”€ Scrape: Today only                               â”‚
â”‚    â””â”€ Action: Update actuals only                      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ What We're Building

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ New System (scraper_2.2/)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ BULK FETCH (Every 4 hours)                             â”‚
â”‚ â””â”€ Fetch today + adjacent days                         â”‚
â”‚    â””â”€ Run: bulk_fetcher.py                             â”‚
â”‚    â””â”€ Cache to JSON/SQLite                             â”‚
â”‚    â””â”€ Insert new events to DB                          â”‚
â”‚                                                         â”‚
â”‚ REAL-TIME (Every 5 minutes)                            â”‚
â”‚ â””â”€ Read cached today's events                          â”‚
â”‚    â””â”€ Run: realtime_updater.py                         â”‚
â”‚    â””â”€ Fetch only actuals                               â”‚
â”‚    â””â”€ Update DB + cache if changed                     â”‚
â”‚                                                         â”‚
â”‚ BENEFIT: 97% fewer browser loads                       â”‚
â”‚          Faster 5-minute updates                       â”‚
â”‚          Smarter caching strategy                      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Core Concepts

### HTML Parsing (What We're Scraping)

```html
<tr class="calendar__row">
  <td>Date</td>           <!-- Nov 7 -->
  <td>Time</td>           <!-- 13:30 -->
  <td>Currency</td>       <!-- USD -->
  <td>Impact</td>         <!-- â­â­â­ -->
  <td>Event Title</td>    <!-- CPI Release -->
  <td>Actual</td>         <!-- 3.2% (or empty if not released) -->
  <td>Forecast</td>       <!-- 3.1% -->
  <td>Previous</td>       <!-- 3.0% -->
</tr>
```

### Database Schema

```sql
Economic_Calendar_FF (
  date           DATE,
  time           TEXT,
  currency       TEXT,          -- USD, EUR, GBP, JPY, etc.
  impact         TEXT,          -- high, medium, low, unknown
  event          TEXT,          -- Event name
  actual         TEXT,          -- Released value (empty until event)
  forecast       TEXT,          -- Expected value
  previous       TEXT,          -- Previous period value
  created_at     TIMESTAMP,
  updated_at     TIMESTAMP,
  PRIMARY KEY (date, currency, event)  -- Prevents duplicates
)
```

### Job Execution Pattern

```python
# Pattern used by all jobs
1. Load configuration (config.yaml + .env)
2. Initialize scraper
3. Fetch data from ForexFactory
4. Transform data (parse HTML, classify impact)
5. Connect to database
6. Insert/Update records
7. Log results to sync_log table
8. Handle errors and cleanup
```

---

## ğŸ“ Key Files Summary

| File | Lines | Purpose | Status |
|------|-------|---------|--------|
| `SCRAPER_ARCHITECTURE_ANALYSIS.md` | 300+ | System analysis | âœ… Done |
| `PROJECT_STRUCTURE.md` | 400+ | Development roadmap | âœ… Done |
| `REORGANIZATION_SUMMARY.md` | 350+ | What we did | âœ… Done |
| `scraper_2.2/README.md` | 300+ | Getting started | âœ… Done |
| `old_structure/FINAL_TOOLS_OUTPUT/scraper_core.py` | 308 | Core scraper | âœ… Reference |
| `old_structure/FINAL_TOOLS_OUTPUT/database.py` | 321 | DB operations | âœ… Reference |
| `scraper_2.2/src/scraper.py` | TBD | New scraper | â³ To build |
| `scraper_2.2/src/cache.py` | TBD | New cache | â³ To build |
| `scraper_2.2/src/database.py` | TBD | New database | â³ To build |
| `scraper_2.2/jobs/bulk_fetcher.py` | TBD | Bulk fetch job | â³ To build |
| `scraper_2.2/jobs/realtime_updater.py` | TBD | Real-time job | â³ To build |

---

## ğŸ¯ Development Checklist

### Phase 1: Setup âœ…
- [x] Analyze old system
- [x] Organize directories
- [x] Create documentation
- [x] Set up structure

### Phase 2: Core Implementation â³
- [ ] Implement scraper.py
- [ ] Implement cache.py
- [ ] Implement database.py
- [ ] Test core components

### Phase 3: Jobs â³
- [ ] Implement bulk_fetcher.py
- [ ] Implement realtime_updater.py
- [ ] Implement scheduler.py

### Phase 4: Quality â³
- [ ] Write unit tests
- [ ] Test manually
- [ ] Handle edge cases
- [ ] Document architecture

### Phase 5: Deployment â³
- [ ] Configure GitHub Actions
- [ ] Deploy to production
- [ ] Monitor job runs
- [ ] Validate data quality

---

## ğŸš€ Getting Started (TL;DR)

### Step 1: Read Documentation (30 min)
```bash
1. This file (STRUCTURE_AT_A_GLANCE.md) - 5 min
2. SCRAPER_ARCHITECTURE_ANALYSIS.md - 15 min
3. scraper_2.2/README.md - 10 min
```

### Step 2: Study Old Code (45 min)
```bash
1. old_structure/FINAL_TOOLS_OUTPUT/scraper_core.py - 20 min
2. old_structure/FINAL_TOOLS_OUTPUT/database.py - 15 min
3. old_structure/FINAL_TOOLS_OUTPUT/daily_sync.py - 10 min
```

### Step 3: Setup Environment (15 min)
```bash
cd scraper_2.2/
cp .env.example .env
cp config.yaml.example config.yaml
# Edit .env and config.yaml
pip install -r requirements.txt
```

### Step 4: Implement (3-5 days)
```bash
1. src/scraper.py - 1 day
2. src/cache.py - 1 day
3. src/database.py - 1 day
4. jobs/ - 1-2 days
5. tests/ - 1 day
```

### Step 5: Deploy (1 day)
```bash
1. Test manually
2. Configure GitHub Actions
3. Monitor first runs
4. Validate data quality
```

---

## ğŸ’¾ File Locations Reference

| What | Location |
|------|----------|
| System analysis | `SCRAPER_ARCHITECTURE_ANALYSIS.md` |
| Development plan | `PROJECT_STRUCTURE.md` |
| Organization summary | `REORGANIZATION_SUMMARY.md` |
| This quick ref | `STRUCTURE_AT_A_GLANCE.md` |
| New code | `scraper_2.2/` |
| Old code (ref) | `old_structure/FINAL_TOOLS_OUTPUT/` |
| Workflows | `.github/workflows/` |
| Logs | `scraper_2.2/logs/` |

---

## ğŸ“ Common Questions

**Q: Should I modify old_structure/?**
A: No. Read it to learn, don't modify. Build new code in scraper_2.2/

**Q: Where do I start coding?**
A: Start with scraper_2.2/src/scraper.py (reference old scraper_core.py)

**Q: How do I understand the database?**
A: Read old_structure/FINAL_TOOLS_OUTPUT/database.py (321 lines, well-commented)

**Q: Can I keep using the old system?**
A: Yes! Both systems can coexist. New system improves on old.

**Q: What's the caching optimization?**
A: Bulk fetch every 4 hours, filter for today every 5 minutes (97% fewer page loads)

**Q: How long to implement?**
A: 3-5 days for full implementation + testing

---

## âœ¨ What's Ready Now

- âœ… Complete architecture analysis
- âœ… Detailed development roadmap
- âœ… Organized file structure
- âœ… Getting started guides
- âœ… Reference materials
- âœ… Documentation

## â³ What's Next

- â³ Implement scraper_2.2/src/ components
- â³ Implement scraper_2.2/jobs/ scripts
- â³ Write tests
- â³ Deploy and monitor

---

**Last Updated:** November 8, 2025
**Status:** Ready for implementation

Start with: `SCRAPER_ARCHITECTURE_ANALYSIS.md` ğŸ“–
